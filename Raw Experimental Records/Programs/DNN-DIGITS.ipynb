{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2aa4c1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (l1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (l2): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "Epoch:  1 | Acc: 0.1767 | F1: 0.1221 | MCC: 0.0949 | MS Loss: 0.0935 | CE Loss: 2.4683 | Score: 0.5300 | Test: 0.1822\n",
      "Epoch:  2 | Acc: 0.1960 | F1: 0.1365 | MCC: 0.1280 | MS Loss: 0.0890 | CE Loss: 2.1563 | Score: 0.6516 | Test: 0.1667\n",
      "Epoch:  3 | Acc: 0.3430 | F1: 0.3004 | MCC: 0.2909 | MS Loss: 0.0786 | CE Loss: 1.8503 | Score: 0.6327 | Test: 0.3111\n",
      "Epoch:  4 | Acc: 0.5256 | F1: 0.4690 | MCC: 0.4825 | MS Loss: 0.0681 | CE Loss: 1.5362 | Score: 0.6984 | Test: 0.4978\n",
      "Epoch:  5 | Acc: 0.6451 | F1: 0.6127 | MCC: 0.6107 | MS Loss: 0.0584 | CE Loss: 1.2756 | Score: 0.7058 | Test: 0.6133\n",
      "Epoch:  6 | Acc: 0.7157 | F1: 0.6987 | MCC: 0.6896 | MS Loss: 0.0499 | CE Loss: 1.0764 | Score: 0.6159 | Test: 0.7022\n",
      "Epoch:  7 | Acc: 0.7402 | F1: 0.7270 | MCC: 0.7195 | MS Loss: 0.0435 | CE Loss: 0.9283 | Score: 0.5621 | Test: 0.7244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Download\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Download\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Download\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Download\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8 | Acc: 0.7958 | F1: 0.7901 | MCC: 0.7781 | MS Loss: 0.0363 | CE Loss: 0.7794 | Score: 0.4793 | Test: 0.7622\n",
      "Epoch:  9 | Acc: 0.8337 | F1: 0.8314 | MCC: 0.8171 | MS Loss: 0.0293 | CE Loss: 0.6441 | Score: 0.3893 | Test: 0.8200\n",
      "Epoch:  10 | Acc: 0.8582 | F1: 0.8577 | MCC: 0.8428 | MS Loss: 0.0249 | CE Loss: 0.5537 | Score: 0.3337 | Test: 0.8489\n",
      "Epoch:  11 | Acc: 0.8612 | F1: 0.8600 | MCC: 0.8463 | MS Loss: 0.0226 | CE Loss: 0.4980 | Score: 0.2995 | Test: 0.8644\n",
      "Epoch:  12 | Acc: 0.8604 | F1: 0.8592 | MCC: 0.8458 | MS Loss: 0.0206 | CE Loss: 0.4490 | Score: 0.2856 | Test: 0.8622\n",
      "Epoch:  13 | Acc: 0.8857 | F1: 0.8856 | MCC: 0.8735 | MS Loss: 0.0181 | CE Loss: 0.3975 | Score: 0.2598 | Test: 0.8778\n",
      "Epoch:  14 | Acc: 0.8990 | F1: 0.8999 | MCC: 0.8880 | MS Loss: 0.0161 | CE Loss: 0.3566 | Score: 0.2329 | Test: 0.9044\n",
      "Epoch:  15 | Acc: 0.9020 | F1: 0.9027 | MCC: 0.8913 | MS Loss: 0.0149 | CE Loss: 0.3323 | Score: 0.2277 | Test: 0.9067\n",
      "Epoch:  16 | Acc: 0.9087 | F1: 0.9090 | MCC: 0.8991 | MS Loss: 0.0141 | CE Loss: 0.3129 | Score: 0.2243 | Test: 0.9044\n",
      "Epoch:  17 | Acc: 0.9161 | F1: 0.9164 | MCC: 0.9070 | MS Loss: 0.0131 | CE Loss: 0.2884 | Score: 0.2080 | Test: 0.9089\n",
      "Epoch:  18 | Acc: 0.9228 | F1: 0.9231 | MCC: 0.9143 | MS Loss: 0.0119 | CE Loss: 0.2624 | Score: 0.1984 | Test: 0.9133\n",
      "Epoch:  19 | Acc: 0.9287 | F1: 0.9292 | MCC: 0.9208 | MS Loss: 0.0110 | CE Loss: 0.2403 | Score: 0.1921 | Test: 0.9267\n",
      "Epoch:  20 | Acc: 0.9362 | F1: 0.9366 | MCC: 0.9291 | MS Loss: 0.0103 | CE Loss: 0.2237 | Score: 0.1703 | Test: 0.9356\n",
      "Epoch:  21 | Acc: 0.9376 | F1: 0.9379 | MCC: 0.9307 | MS Loss: 0.0099 | CE Loss: 0.2126 | Score: 0.1587 | Test: 0.9444\n",
      "Epoch:  22 | Acc: 0.9428 | F1: 0.9432 | MCC: 0.9366 | MS Loss: 0.0095 | CE Loss: 0.2038 | Score: 0.1427 | Test: 0.9444\n",
      "Epoch:  23 | Acc: 0.9436 | F1: 0.9438 | MCC: 0.9374 | MS Loss: 0.0089 | CE Loss: 0.1941 | Score: 0.1556 | Test: 0.9467\n",
      "Epoch:  24 | Acc: 0.9436 | F1: 0.9438 | MCC: 0.9374 | MS Loss: 0.0084 | CE Loss: 0.1839 | Score: 0.1478 | Test: 0.9511\n",
      "Epoch:  25 | Acc: 0.9495 | F1: 0.9496 | MCC: 0.9439 | MS Loss: 0.0079 | CE Loss: 0.1746 | Score: 0.1424 | Test: 0.9511\n",
      "Epoch:  26 | Acc: 0.9547 | F1: 0.9548 | MCC: 0.9497 | MS Loss: 0.0075 | CE Loss: 0.1668 | Score: 0.1340 | Test: 0.9556\n",
      "Epoch:  27 | Acc: 0.9555 | F1: 0.9555 | MCC: 0.9505 | MS Loss: 0.0072 | CE Loss: 0.1602 | Score: 0.1209 | Test: 0.9489\n",
      "Epoch:  28 | Acc: 0.9577 | F1: 0.9578 | MCC: 0.9530 | MS Loss: 0.0069 | CE Loss: 0.1540 | Score: 0.1132 | Test: 0.9489\n",
      "Epoch:  29 | Acc: 0.9599 | F1: 0.9600 | MCC: 0.9555 | MS Loss: 0.0066 | CE Loss: 0.1477 | Score: 0.1028 | Test: 0.9533\n",
      "Epoch:  30 | Acc: 0.9636 | F1: 0.9638 | MCC: 0.9596 | MS Loss: 0.0063 | CE Loss: 0.1415 | Score: 0.0993 | Test: 0.9511\n",
      "Epoch:  31 | Acc: 0.9629 | F1: 0.9630 | MCC: 0.9588 | MS Loss: 0.0061 | CE Loss: 0.1361 | Score: 0.0880 | Test: 0.9644\n",
      "Epoch:  32 | Acc: 0.9651 | F1: 0.9651 | MCC: 0.9613 | MS Loss: 0.0058 | CE Loss: 0.1305 | Score: 0.0862 | Test: 0.9644\n",
      "Epoch:  33 | Acc: 0.9673 | F1: 0.9674 | MCC: 0.9637 | MS Loss: 0.0055 | CE Loss: 0.1245 | Score: 0.0828 | Test: 0.9644\n",
      "Epoch:  34 | Acc: 0.9710 | F1: 0.9710 | MCC: 0.9678 | MS Loss: 0.0052 | CE Loss: 0.1189 | Score: 0.0739 | Test: 0.9644\n",
      "Epoch:  35 | Acc: 0.9748 | F1: 0.9748 | MCC: 0.9720 | MS Loss: 0.0050 | CE Loss: 0.1142 | Score: 0.0876 | Test: 0.9667\n",
      "Epoch:  36 | Acc: 0.9748 | F1: 0.9747 | MCC: 0.9720 | MS Loss: 0.0048 | CE Loss: 0.1102 | Score: 0.0789 | Test: 0.9689\n",
      "Epoch:  37 | Acc: 0.9755 | F1: 0.9754 | MCC: 0.9728 | MS Loss: 0.0046 | CE Loss: 0.1064 | Score: 0.0838 | Test: 0.9689\n",
      "Epoch:  38 | Acc: 0.9762 | F1: 0.9762 | MCC: 0.9736 | MS Loss: 0.0045 | CE Loss: 0.1029 | Score: 0.0851 | Test: 0.9711\n",
      "Epoch:  39 | Acc: 0.9770 | F1: 0.9770 | MCC: 0.9744 | MS Loss: 0.0044 | CE Loss: 0.0998 | Score: 0.0733 | Test: 0.9756\n",
      "Epoch:  40 | Acc: 0.9770 | F1: 0.9769 | MCC: 0.9744 | MS Loss: 0.0042 | CE Loss: 0.0967 | Score: 0.0714 | Test: 0.9756\n",
      "Epoch:  41 | Acc: 0.9800 | F1: 0.9799 | MCC: 0.9777 | MS Loss: 0.0040 | CE Loss: 0.0934 | Score: 0.0728 | Test: 0.9733\n",
      "Epoch:  42 | Acc: 0.9785 | F1: 0.9784 | MCC: 0.9761 | MS Loss: 0.0039 | CE Loss: 0.0904 | Score: 0.0679 | Test: 0.9711\n",
      "Epoch:  43 | Acc: 0.9792 | F1: 0.9791 | MCC: 0.9769 | MS Loss: 0.0038 | CE Loss: 0.0880 | Score: 0.0731 | Test: 0.9711\n",
      "Epoch:  44 | Acc: 0.9792 | F1: 0.9791 | MCC: 0.9769 | MS Loss: 0.0037 | CE Loss: 0.0858 | Score: 0.0664 | Test: 0.9689\n",
      "Epoch:  45 | Acc: 0.9822 | F1: 0.9821 | MCC: 0.9802 | MS Loss: 0.0036 | CE Loss: 0.0836 | Score: 0.0649 | Test: 0.9689\n",
      "Epoch:  46 | Acc: 0.9807 | F1: 0.9806 | MCC: 0.9786 | MS Loss: 0.0035 | CE Loss: 0.0812 | Score: 0.0578 | Test: 0.9711\n",
      "Epoch:  47 | Acc: 0.9822 | F1: 0.9820 | MCC: 0.9802 | MS Loss: 0.0033 | CE Loss: 0.0788 | Score: 0.0563 | Test: 0.9733\n",
      "Epoch:  48 | Acc: 0.9822 | F1: 0.9820 | MCC: 0.9802 | MS Loss: 0.0032 | CE Loss: 0.0765 | Score: 0.0481 | Test: 0.9756\n",
      "Epoch:  49 | Acc: 0.9829 | F1: 0.9828 | MCC: 0.9811 | MS Loss: 0.0032 | CE Loss: 0.0745 | Score: 0.0475 | Test: 0.9733\n",
      "Epoch:  50 | Acc: 0.9829 | F1: 0.9827 | MCC: 0.9811 | MS Loss: 0.0031 | CE Loss: 0.0725 | Score: 0.0468 | Test: 0.9733\n",
      "Epoch:  51 | Acc: 0.9829 | F1: 0.9828 | MCC: 0.9810 | MS Loss: 0.0030 | CE Loss: 0.0704 | Score: 0.0456 | Test: 0.9733\n",
      "Epoch:  52 | Acc: 0.9829 | F1: 0.9827 | MCC: 0.9810 | MS Loss: 0.0029 | CE Loss: 0.0684 | Score: 0.0450 | Test: 0.9733\n",
      "Epoch:  53 | Acc: 0.9822 | F1: 0.9820 | MCC: 0.9802 | MS Loss: 0.0029 | CE Loss: 0.0666 | Score: 0.0442 | Test: 0.9733\n",
      "Epoch:  54 | Acc: 0.9822 | F1: 0.9820 | MCC: 0.9802 | MS Loss: 0.0028 | CE Loss: 0.0649 | Score: 0.0438 | Test: 0.9733\n",
      "Epoch:  55 | Acc: 0.9829 | F1: 0.9827 | MCC: 0.9810 | MS Loss: 0.0027 | CE Loss: 0.0632 | Score: 0.0409 | Test: 0.9733\n",
      "Epoch:  56 | Acc: 0.9844 | F1: 0.9843 | MCC: 0.9827 | MS Loss: 0.0026 | CE Loss: 0.0615 | Score: 0.0396 | Test: 0.9733\n",
      "Epoch:  57 | Acc: 0.9844 | F1: 0.9842 | MCC: 0.9827 | MS Loss: 0.0025 | CE Loss: 0.0599 | Score: 0.0384 | Test: 0.9733\n",
      "Epoch:  58 | Acc: 0.9859 | F1: 0.9857 | MCC: 0.9843 | MS Loss: 0.0025 | CE Loss: 0.0584 | Score: 0.0378 | Test: 0.9733\n",
      "Epoch:  59 | Acc: 0.9866 | F1: 0.9865 | MCC: 0.9852 | MS Loss: 0.0024 | CE Loss: 0.0571 | Score: 0.0368 | Test: 0.9756\n",
      "Epoch:  60 | Acc: 0.9874 | F1: 0.9873 | MCC: 0.9860 | MS Loss: 0.0023 | CE Loss: 0.0557 | Score: 0.0361 | Test: 0.9756\n",
      "Epoch:  61 | Acc: 0.9874 | F1: 0.9872 | MCC: 0.9860 | MS Loss: 0.0023 | CE Loss: 0.0545 | Score: 0.0357 | Test: 0.9756\n",
      "Epoch:  62 | Acc: 0.9874 | F1: 0.9872 | MCC: 0.9860 | MS Loss: 0.0022 | CE Loss: 0.0532 | Score: 0.0417 | Test: 0.9778\n",
      "Epoch:  63 | Acc: 0.9874 | F1: 0.9872 | MCC: 0.9860 | MS Loss: 0.0022 | CE Loss: 0.0519 | Score: 0.0419 | Test: 0.9778\n",
      "Epoch:  64 | Acc: 0.9889 | F1: 0.9888 | MCC: 0.9876 | MS Loss: 0.0021 | CE Loss: 0.0507 | Score: 0.0413 | Test: 0.9778\n",
      "Epoch:  65 | Acc: 0.9889 | F1: 0.9888 | MCC: 0.9876 | MS Loss: 0.0020 | CE Loss: 0.0495 | Score: 0.0412 | Test: 0.9778\n",
      "Epoch:  66 | Acc: 0.9889 | F1: 0.9887 | MCC: 0.9876 | MS Loss: 0.0020 | CE Loss: 0.0484 | Score: 0.0407 | Test: 0.9778\n",
      "Epoch:  67 | Acc: 0.9889 | F1: 0.9887 | MCC: 0.9876 | MS Loss: 0.0019 | CE Loss: 0.0474 | Score: 0.0398 | Test: 0.9778\n",
      "Epoch:  68 | Acc: 0.9896 | F1: 0.9895 | MCC: 0.9885 | MS Loss: 0.0019 | CE Loss: 0.0463 | Score: 0.0333 | Test: 0.9778\n",
      "Epoch:  69 | Acc: 0.9911 | F1: 0.9909 | MCC: 0.9901 | MS Loss: 0.0018 | CE Loss: 0.0453 | Score: 0.0325 | Test: 0.9778\n",
      "Epoch:  70 | Acc: 0.9911 | F1: 0.9909 | MCC: 0.9901 | MS Loss: 0.0018 | CE Loss: 0.0444 | Score: 0.0319 | Test: 0.9778\n",
      "Epoch:  71 | Acc: 0.9911 | F1: 0.9909 | MCC: 0.9901 | MS Loss: 0.0017 | CE Loss: 0.0434 | Score: 0.0315 | Test: 0.9778\n",
      "Epoch:  72 | Acc: 0.9911 | F1: 0.9909 | MCC: 0.9901 | MS Loss: 0.0017 | CE Loss: 0.0425 | Score: 0.0309 | Test: 0.9778\n",
      "Epoch:  73 | Acc: 0.9926 | F1: 0.9924 | MCC: 0.9918 | MS Loss: 0.0016 | CE Loss: 0.0417 | Score: 0.0303 | Test: 0.9778\n",
      "Epoch:  74 | Acc: 0.9926 | F1: 0.9924 | MCC: 0.9918 | MS Loss: 0.0016 | CE Loss: 0.0408 | Score: 0.0297 | Test: 0.9778\n",
      "Epoch:  75 | Acc: 0.9926 | F1: 0.9924 | MCC: 0.9918 | MS Loss: 0.0015 | CE Loss: 0.0400 | Score: 0.0294 | Test: 0.9778\n",
      "Epoch:  76 | Acc: 0.9941 | F1: 0.9939 | MCC: 0.9934 | MS Loss: 0.0015 | CE Loss: 0.0392 | Score: 0.0288 | Test: 0.9778\n",
      "Epoch:  77 | Acc: 0.9948 | F1: 0.9947 | MCC: 0.9942 | MS Loss: 0.0014 | CE Loss: 0.0384 | Score: 0.0282 | Test: 0.9778\n",
      "Epoch:  78 | Acc: 0.9948 | F1: 0.9947 | MCC: 0.9942 | MS Loss: 0.0014 | CE Loss: 0.0376 | Score: 0.0275 | Test: 0.9778\n",
      "Epoch:  79 | Acc: 0.9948 | F1: 0.9947 | MCC: 0.9942 | MS Loss: 0.0014 | CE Loss: 0.0369 | Score: 0.0272 | Test: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  80 | Acc: 0.9948 | F1: 0.9947 | MCC: 0.9942 | MS Loss: 0.0013 | CE Loss: 0.0362 | Score: 0.0266 | Test: 0.9778\n",
      "Epoch:  81 | Acc: 0.9948 | F1: 0.9947 | MCC: 0.9942 | MS Loss: 0.0013 | CE Loss: 0.0355 | Score: 0.0262 | Test: 0.9778\n",
      "Epoch:  82 | Acc: 0.9948 | F1: 0.9947 | MCC: 0.9942 | MS Loss: 0.0012 | CE Loss: 0.0348 | Score: 0.0256 | Test: 0.9778\n",
      "Epoch:  83 | Acc: 0.9955 | F1: 0.9954 | MCC: 0.9951 | MS Loss: 0.0012 | CE Loss: 0.0342 | Score: 0.0251 | Test: 0.9800\n",
      "Epoch:  84 | Acc: 0.9955 | F1: 0.9954 | MCC: 0.9951 | MS Loss: 0.0012 | CE Loss: 0.0335 | Score: 0.0248 | Test: 0.9800\n",
      "Epoch:  85 | Acc: 0.9955 | F1: 0.9954 | MCC: 0.9951 | MS Loss: 0.0011 | CE Loss: 0.0329 | Score: 0.0243 | Test: 0.9800\n",
      "Epoch:  86 | Acc: 0.9963 | F1: 0.9962 | MCC: 0.9959 | MS Loss: 0.0011 | CE Loss: 0.0323 | Score: 0.0240 | Test: 0.9800\n",
      "Epoch:  87 | Acc: 0.9963 | F1: 0.9962 | MCC: 0.9959 | MS Loss: 0.0011 | CE Loss: 0.0317 | Score: 0.0236 | Test: 0.9800\n",
      "Epoch:  88 | Acc: 0.9963 | F1: 0.9962 | MCC: 0.9959 | MS Loss: 0.0011 | CE Loss: 0.0311 | Score: 0.0232 | Test: 0.9800\n",
      "Epoch:  89 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0010 | CE Loss: 0.0306 | Score: 0.0228 | Test: 0.9778\n",
      "Epoch:  90 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0010 | CE Loss: 0.0300 | Score: 0.0226 | Test: 0.9778\n",
      "Epoch:  91 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0010 | CE Loss: 0.0295 | Score: 0.0222 | Test: 0.9778\n",
      "Epoch:  92 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0010 | CE Loss: 0.0290 | Score: 0.0219 | Test: 0.9778\n",
      "Epoch:  93 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0009 | CE Loss: 0.0285 | Score: 0.0215 | Test: 0.9778\n",
      "Epoch:  94 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0009 | CE Loss: 0.0280 | Score: 0.0153 | Test: 0.9778\n",
      "Epoch:  95 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0009 | CE Loss: 0.0275 | Score: 0.0151 | Test: 0.9778\n",
      "Epoch:  96 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0009 | CE Loss: 0.0270 | Score: 0.0148 | Test: 0.9778\n",
      "Epoch:  97 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0008 | CE Loss: 0.0266 | Score: 0.0146 | Test: 0.9756\n",
      "Epoch:  98 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0008 | CE Loss: 0.0261 | Score: 0.0143 | Test: 0.9756\n",
      "Epoch:  99 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0008 | CE Loss: 0.0257 | Score: 0.0141 | Test: 0.9756\n",
      "Epoch:  100 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0008 | CE Loss: 0.0253 | Score: 0.0137 | Test: 0.9756\n",
      "Epoch:  101 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0008 | CE Loss: 0.0248 | Score: 0.0135 | Test: 0.9756\n",
      "Epoch:  102 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0007 | CE Loss: 0.0244 | Score: 0.0132 | Test: 0.9756\n",
      "Epoch:  103 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0007 | CE Loss: 0.0240 | Score: 0.0129 | Test: 0.9756\n",
      "Epoch:  104 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0007 | CE Loss: 0.0237 | Score: 0.0128 | Test: 0.9756\n",
      "Epoch:  105 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0007 | CE Loss: 0.0233 | Score: 0.0126 | Test: 0.9756\n",
      "Epoch:  106 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0007 | CE Loss: 0.0229 | Score: 0.0122 | Test: 0.9756\n",
      "Epoch:  107 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0007 | CE Loss: 0.0225 | Score: 0.0120 | Test: 0.9756\n",
      "Epoch:  108 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0006 | CE Loss: 0.0222 | Score: 0.0117 | Test: 0.9756\n",
      "Epoch:  109 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0006 | CE Loss: 0.0218 | Score: 0.0115 | Test: 0.9756\n",
      "Epoch:  110 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0006 | CE Loss: 0.0215 | Score: 0.0113 | Test: 0.9756\n",
      "Epoch:  111 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0006 | CE Loss: 0.0212 | Score: 0.0109 | Test: 0.9756\n",
      "Epoch:  112 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0006 | CE Loss: 0.0208 | Score: 0.0108 | Test: 0.9756\n",
      "Epoch:  113 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0006 | CE Loss: 0.0205 | Score: 0.0107 | Test: 0.9756\n",
      "Epoch:  114 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0006 | CE Loss: 0.0202 | Score: 0.0105 | Test: 0.9756\n",
      "Epoch:  115 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0006 | CE Loss: 0.0199 | Score: 0.0103 | Test: 0.9756\n",
      "Epoch:  116 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0005 | CE Loss: 0.0196 | Score: 0.0100 | Test: 0.9756\n",
      "Epoch:  117 | Acc: 0.9978 | F1: 0.9977 | MCC: 0.9975 | MS Loss: 0.0005 | CE Loss: 0.0193 | Score: 0.0098 | Test: 0.9733\n",
      "Epoch:  118 | Acc: 0.9978 | F1: 0.9978 | MCC: 0.9975 | MS Loss: 0.0005 | CE Loss: 0.0190 | Score: 0.0096 | Test: 0.9733\n",
      "Epoch:  119 | Acc: 0.9978 | F1: 0.9978 | MCC: 0.9975 | MS Loss: 0.0005 | CE Loss: 0.0187 | Score: 0.0094 | Test: 0.9733\n",
      "Epoch:  120 | Acc: 0.9978 | F1: 0.9978 | MCC: 0.9975 | MS Loss: 0.0005 | CE Loss: 0.0184 | Score: 0.0092 | Test: 0.9733\n",
      "Epoch:  121 | Acc: 0.9978 | F1: 0.9978 | MCC: 0.9975 | MS Loss: 0.0005 | CE Loss: 0.0182 | Score: 0.0091 | Test: 0.9733\n",
      "Epoch:  122 | Acc: 0.9978 | F1: 0.9978 | MCC: 0.9975 | MS Loss: 0.0005 | CE Loss: 0.0179 | Score: 0.0088 | Test: 0.9733\n",
      "Epoch:  123 | Acc: 0.9978 | F1: 0.9978 | MCC: 0.9975 | MS Loss: 0.0005 | CE Loss: 0.0176 | Score: 0.0087 | Test: 0.9733\n",
      "Epoch:  124 | Acc: 0.9978 | F1: 0.9978 | MCC: 0.9975 | MS Loss: 0.0005 | CE Loss: 0.0174 | Score: 0.0085 | Test: 0.9756\n",
      "Epoch:  125 | Acc: 0.9978 | F1: 0.9978 | MCC: 0.9975 | MS Loss: 0.0004 | CE Loss: 0.0171 | Score: 0.0084 | Test: 0.9756\n",
      "Epoch:  126 | Acc: 0.9978 | F1: 0.9978 | MCC: 0.9975 | MS Loss: 0.0004 | CE Loss: 0.0169 | Score: 0.0082 | Test: 0.9756\n",
      "Epoch:  127 | Acc: 0.9978 | F1: 0.9978 | MCC: 0.9975 | MS Loss: 0.0004 | CE Loss: 0.0166 | Score: 0.0081 | Test: 0.9756\n",
      "Epoch:  128 | Acc: 0.9993 | F1: 0.9993 | MCC: 0.9992 | MS Loss: 0.0004 | CE Loss: 0.0164 | Score: 0.0080 | Test: 0.9756\n",
      "Epoch:  129 | Acc: 0.9993 | F1: 0.9993 | MCC: 0.9992 | MS Loss: 0.0004 | CE Loss: 0.0162 | Score: 0.0079 | Test: 0.9756\n",
      "Epoch:  130 | Acc: 0.9993 | F1: 0.9993 | MCC: 0.9992 | MS Loss: 0.0004 | CE Loss: 0.0159 | Score: 0.0076 | Test: 0.9756\n",
      "Epoch:  131 | Acc: 0.9993 | F1: 0.9993 | MCC: 0.9992 | MS Loss: 0.0004 | CE Loss: 0.0157 | Score: 0.0075 | Test: 0.9756\n",
      "Epoch:  132 | Acc: 0.9993 | F1: 0.9993 | MCC: 0.9992 | MS Loss: 0.0004 | CE Loss: 0.0155 | Score: 0.0074 | Test: 0.9756\n",
      "Epoch:  133 | Acc: 0.9993 | F1: 0.9993 | MCC: 0.9992 | MS Loss: 0.0004 | CE Loss: 0.0153 | Score: 0.0073 | Test: 0.9756\n",
      "Epoch:  134 | Acc: 0.9993 | F1: 0.9993 | MCC: 0.9992 | MS Loss: 0.0004 | CE Loss: 0.0151 | Score: 0.0072 | Test: 0.9756\n",
      "Epoch:  135 | Acc: 0.9993 | F1: 0.9993 | MCC: 0.9992 | MS Loss: 0.0004 | CE Loss: 0.0148 | Score: 0.0071 | Test: 0.9756\n",
      "Epoch:  136 | Acc: 0.9993 | F1: 0.9993 | MCC: 0.9992 | MS Loss: 0.0003 | CE Loss: 0.0146 | Score: 0.0069 | Test: 0.9756\n",
      "Epoch:  137 | Acc: 0.9993 | F1: 0.9993 | MCC: 0.9992 | MS Loss: 0.0003 | CE Loss: 0.0144 | Score: 0.0067 | Test: 0.9756\n",
      "Epoch:  138 | Acc: 0.9993 | F1: 0.9993 | MCC: 0.9992 | MS Loss: 0.0003 | CE Loss: 0.0142 | Score: 0.0065 | Test: 0.9756\n",
      "Epoch:  139 | Acc: 0.9993 | F1: 0.9993 | MCC: 0.9992 | MS Loss: 0.0003 | CE Loss: 0.0140 | Score: 0.0064 | Test: 0.9756\n",
      "Epoch:  140 | Acc: 0.9993 | F1: 0.9993 | MCC: 0.9992 | MS Loss: 0.0003 | CE Loss: 0.0138 | Score: 0.0064 | Test: 0.9756\n",
      "Epoch:  141 | Acc: 0.9993 | F1: 0.9993 | MCC: 0.9992 | MS Loss: 0.0003 | CE Loss: 0.0137 | Score: 0.0064 | Test: 0.9756\n",
      "Epoch:  142 | Acc: 0.9993 | F1: 0.9993 | MCC: 0.9992 | MS Loss: 0.0003 | CE Loss: 0.0135 | Score: 0.0062 | Test: 0.9756\n",
      "Epoch:  143 | Acc: 0.9993 | F1: 0.9993 | MCC: 0.9992 | MS Loss: 0.0003 | CE Loss: 0.0133 | Score: 0.0060 | Test: 0.9756\n",
      "Epoch:  144 | Acc: 0.9993 | F1: 0.9993 | MCC: 0.9992 | MS Loss: 0.0003 | CE Loss: 0.0131 | Score: 0.0060 | Test: 0.9778\n",
      "Epoch:  145 | Acc: 0.9993 | F1: 0.9993 | MCC: 0.9992 | MS Loss: 0.0003 | CE Loss: 0.0129 | Score: 0.0059 | Test: 0.9778\n",
      "Epoch:  146 | Acc: 0.9993 | F1: 0.9993 | MCC: 0.9992 | MS Loss: 0.0003 | CE Loss: 0.0128 | Score: 0.0056 | Test: 0.9778\n",
      "Epoch:  147 | Acc: 0.9993 | F1: 0.9993 | MCC: 0.9992 | MS Loss: 0.0003 | CE Loss: 0.0126 | Score: 0.0056 | Test: 0.9778\n",
      "Epoch:  148 | Acc: 1.0000 | F1: 1.0000 | MCC: 1.0000 | MS Loss: 0.0003 | CE Loss: 0.0124 | Score: 0.0055 | Test: 0.9778\n",
      "Epoch:  149 | Acc: 1.0000 | F1: 1.0000 | MCC: 1.0000 | MS Loss: 0.0003 | CE Loss: 0.0123 | Score: 0.0055 | Test: 0.9778\n",
      "Epoch:  150 | Acc: 1.0000 | F1: 1.0000 | MCC: 1.0000 | MS Loss: 0.0002 | CE Loss: 0.0121 | Score: 0.0054 | Test: 0.9778\n",
      "\n",
      "Average Time Cost:  \n",
      "Acc: 0.00027268 \n",
      "F1: 0.00163585 \n",
      "MCC: 0.00261941 \n",
      "MS Loss: 0.00048552 \n",
      "CE Loss: 0.00039248 \n",
      "Score: 0.01366331\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score\n",
    "import numpy as np\n",
    "import itertools\n",
    "from itertools import permutations, combinations\n",
    "import time\n",
    "from pylab import *\n",
    "\n",
    "torch.manual_seed(1)                      # reproducible\n",
    "torch.set_printoptions(threshold=np.inf)  # print all\n",
    "\n",
    "def findByRow(mat, row):\n",
    "    return np.where((mat == row).all(1))[0]\n",
    "\n",
    "\n",
    "# ----- Step 1: Set Hyper Parameters ----- #\n",
    "\n",
    "NAME = 'DNN-DIGIST'\n",
    "OUTPUT_CLASS = 10\n",
    "\n",
    "RELEASE_LISTS = [\n",
    "    [2,3],\n",
    "    [3,2]\n",
    "]\n",
    "RELEASE_FACTOR = 0.1\n",
    "\n",
    "LR = 0.01\n",
    "TURNS = 150\n",
    "\n",
    "K = 3\n",
    "T = 20\n",
    "\n",
    "K_release = K-1\n",
    "T_max = T-1\n",
    "\n",
    "\n",
    "# ----- Step 2: Load MNIST Dataset and Create Loader ----- #\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(digits.data, digits.target, test_size=0.25)\n",
    "x_train, x_test = torch.tensor(X_train, dtype=torch.float), torch.tensor(X_test, dtype=torch.float)\n",
    "y_train, y_test = torch.tensor(Y_train, dtype=torch.long), torch.tensor(Y_test, dtype=torch.long)\n",
    "\n",
    "train_Y = y_train.numpy()\n",
    "test_Y = y_test.numpy()\n",
    "\n",
    "y_train_onehot = torch.nn.functional.one_hot(y_train)\n",
    "\n",
    "\n",
    "# ----- Step 3: Create Model Class ----- #\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(64, 32)\n",
    "        self.l2 = torch.nn.Linear(32, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 64)\n",
    "        x = F.relu(self.l1(x))\n",
    "        return self.l2(x)\n",
    "\n",
    "\n",
    "# ----- Step 4: Instantiate ----- #\n",
    "\n",
    "model = Net()\n",
    "print(model)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "MS_loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "# ----- Step 5: Model Training ----- #\n",
    "\n",
    "turns_record = []\n",
    "loss_record = []\n",
    "MS_loss_record = []\n",
    "train_acc_record = []\n",
    "precision_record = []\n",
    "recall_record = []\n",
    "F1_record = []\n",
    "MCC_record = []\n",
    "AUC_record = []\n",
    "Score_record = []\n",
    "\n",
    "total_loss_time = 0\n",
    "total_MS_loss_time = 0\n",
    "total_acc_time = 0\n",
    "total_precision_time = 0\n",
    "total_recall_time = 0\n",
    "total_F1_time = 0\n",
    "total_MCC_time = 0\n",
    "total_AUC_time = 0\n",
    "total_Score_time = 0\n",
    "\n",
    "# Y轴 输出分类结果的模式\n",
    "# class_list = [item for item in range(OUTPUT_CLASS)]\n",
    "# class_pattern = list(itertools.permutations(class_list, K))\n",
    "# class_pattern_len = len(class_pattern)\n",
    "# print(class_pattern)\n",
    "\n",
    "# release_matrix = np.ones((len(class_pattern), K))\n",
    "# # print(release_matrix[0])\n",
    "\n",
    "# for i in range(len(class_pattern)):\n",
    "    \n",
    "#     for single_list in RELEASE_LISTS:\n",
    "        \n",
    "#         if set(single_list) <= set(class_pattern[i]) and class_pattern[i][0] in single_list: \n",
    "#             for j in range(1, K):\n",
    "#                 if class_pattern[i][j] in single_list:\n",
    "#                     release_matrix[i][j] = RELEASE_FACTOR\n",
    "\n",
    "# for i in range(len(release_matrix)):\n",
    "#     release_matrix[i][0] = sum(release_matrix[i][1:])\n",
    "#     release_matrix[i] /= sum(release_matrix[i])\n",
    "#     print(release_matrix[i])\n",
    "    \n",
    "#     if RELEASE_FACTOR in release_matrix[i]:\n",
    "#         print(class_pattern[i])\n",
    "#         print(release_matrix[i])            \n",
    "\n",
    "for turns in range(1, TURNS+1):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(x_train)\n",
    "    loss = loss_fn(outputs, y_train)  # criterion\n",
    "    loss.backward()        # backward and compute gradients\n",
    "    optimizer.step()       # apply gradients\n",
    "    \n",
    "    # Shared Part - train_output\n",
    "    SP_trainout_time_part_start = time.time()\n",
    "    train_output = model(x_train)\n",
    "    SP_trainout_time_part_stop = time.time()\n",
    "    \n",
    "    # Shared Part - softmax\n",
    "    SP_softmax_time_part_start = time.time()\n",
    "    train_output_result = F.softmax(train_output, dim=1)  # softmax in last dim\n",
    "    SP_softmax_time_part_stop = time.time()\n",
    "    \n",
    "    # Shared Part - pred_train_y\n",
    "    SP_predy_time_part_start = time.time()\n",
    "    pred_train_y = torch.max(train_output, 1)[1].data.numpy()\n",
    "    SP_predy_time_part_stop = time.time()\n",
    "    \n",
    "    # Acc\n",
    "    acc_time_part_start = time.time()\n",
    "    train_accuracy = float((pred_train_y == train_Y).astype(int).sum()) / float(train_Y.size)\n",
    "    acc_time_part_stop = time.time()\n",
    "    \n",
    "    # MS Loss\n",
    "    MS_loss_time_part_start = time.time()\n",
    "    MS_train_loss = MS_loss_fn(train_output_result, y_train_onehot)\n",
    "    MS_loss_time_part_stop = time.time()\n",
    "    \n",
    "    # CE Loss\n",
    "    loss_time_part_start = time.time()\n",
    "    train_loss = loss_fn(train_output, y_train)\n",
    "    loss_time_part_stop = time.time()\n",
    "    \n",
    "    # Precision\n",
    "    precision_time_part_start = time.time()\n",
    "    precision = precision_score(train_Y, pred_train_y, average='macro')\n",
    "    precision_time_part_stop = time.time()\n",
    "    \n",
    "    # Recall\n",
    "    recall_time_part_start = time.time()\n",
    "    recall = recall_score(train_Y, pred_train_y, average='macro')\n",
    "    recall_time_part_stop = time.time()\n",
    "    \n",
    "    # F1\n",
    "    F1_time_part_start = time.time()\n",
    "    F1 = f1_score(train_Y, pred_train_y, average='macro')\n",
    "    F1_time_part_stop = time.time()\n",
    "    \n",
    "    # MCC\n",
    "    MCC_time_part_start = time.time()\n",
    "    MCC = matthews_corrcoef(train_Y, pred_train_y)\n",
    "    MCC_time_part_stop = time.time()\n",
    "    \n",
    "    # ROC AUC\n",
    "    AUC_time_part_start = time.time()\n",
    "    Y_pred = train_output_result.detach().numpy()\n",
    "    AUC = roc_auc_score(train_Y, Y_pred, average='macro', multi_class='ovr')\n",
    "    AUC_time_part_stop = time.time()\n",
    "    \n",
    "    # Score\n",
    "    Score_time_part_start = time.time()\n",
    "    output_results = train_output_result.detach().numpy()\n",
    "    prediction_pattern = np.argsort(-output_results)[:, :K]  # sorted_states_index\n",
    "#     confidence_pattern =  np.floor((-np.sort(-output_results)[:, :K]) * T)  # sorted_states_t\n",
    "    confidence_pattern = T_max - np.floor((-np.sort(-output_results)[:, :K]) * T)  # sorted_states_t\n",
    "    confidence_pattern[confidence_pattern == -1] = 0\n",
    "\n",
    "    total_score = 0\n",
    "    pattern_num = len(confidence_pattern)\n",
    "    release_factors = np.ones((pattern_num, K))\n",
    "    \n",
    "    for i in range(pattern_num):\n",
    "        current_prediction_pattern = list(prediction_pattern[i])\n",
    "        if train_Y[i] in current_prediction_pattern:\n",
    "            correct_index = current_prediction_pattern.index(train_Y[i])\n",
    "            confidence_pattern[i][correct_index] = T_max - confidence_pattern[i][correct_index]\n",
    "            release_factors[i][correct_index] = K_release\n",
    "            \n",
    "            for release_list in RELEASE_LISTS:\n",
    "                if current_prediction_pattern[correct_index] == release_list[0]:\n",
    "                    for j in range(K):\n",
    "                        if j != correct_index and current_prediction_pattern[j] in release_list[1:]:\n",
    "                            release_factors[i][j] = RELEASE_FACTOR\n",
    "        \n",
    "    release_factors /= release_factors.sum(axis=1).reshape(-1,1)\n",
    "    confidence_pattern[confidence_pattern == 0] = 1e-7\n",
    "    confidence_pattern = -np.log(confidence_pattern / T_max)\n",
    "    total_score = (np.multiply(release_factors, confidence_pattern).sum()) / pattern_num\n",
    "    Score_time_part_stop = time.time()\n",
    "    \n",
    "#     for i in range(pattern_num):\n",
    "# #         release_factors = np.ones(K)\n",
    "#         if train_Y[i] in prediction_pattern[i]:\n",
    "#             correct_index = list(prediction_pattern[i]).index(train_Y[i])\n",
    "# #             correct_index = np.where(prediction_pattern[i] == train_Y[i])\n",
    "#             confidence_pattern[i][correct_index] = T_MAX - confidence_pattern[i][correct_index]\n",
    "#             release_factors[i][correct_index] = K-1\n",
    "            \n",
    "#             for release_list in RELEASE_LISTS:\n",
    "#                 if prediction_pattern[i][correct_index] in release_list:\n",
    "#                     for j in range(K):\n",
    "#                         if j != correct_index and prediction_pattern[i][j] in release_list:\n",
    "#                             release_factors[i][j] = RELEASE_FACTOR\n",
    "\n",
    "#         sorted_states_t[i] /= T\n",
    "#         confidence_pattern[i] = (confidence_pattern[i] - 1) / T\n",
    "        \n",
    "#         print(confidence_pattern)\n",
    "#         release_factors[i] /= sum(release_factors[i])\n",
    "#         total_score += sum(np.multiply(release_factors, sorted_states_t[i]))\n",
    "#         print(\"++++++++++++++++++++++++\")\n",
    "#         print(sorted_states_index[i])\n",
    "#         print(sorted_states_t[i])\n",
    "#         print(train_Y[i])\n",
    "#         print(release_factors)\n",
    "#         print(sorted_states_t[i])\n",
    "    \n",
    "#     total_score /= len(sorted_states_t)\n",
    "#     release_factors = normalize(release_factors, axis=1, norm='sum')\n",
    "#     release_factors = release_factors / release_factors.sum(axis=0)\n",
    "    \n",
    "#     print(release_factors.shape)\n",
    "#     print(release_factors.sum(axis=1).reshape(-1,1).shape)\n",
    "    \n",
    "    # (Test Acc)\n",
    "    test_output = model(x_test)\n",
    "    pred_test_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "    test_accuracy = float((pred_test_y == test_Y).astype(int).sum()) / float(test_Y.size)\n",
    "\n",
    "    print('Epoch: ', turns, '| Acc: %.4f' % train_accuracy, '| F1: %.4f' % F1, '| MCC: %.4f' % MCC, \n",
    "          '| MS Loss: %.4f' % MS_train_loss.data.numpy(), '| CE Loss: %.4f' % train_loss.data.numpy(), \n",
    "          '| Score: %.4f' % total_score, '| Test: %.4f' % test_accuracy)\n",
    "#           '| Precision: %.4f' % precision, '| Recall: %.4f' % recall, '| AUC: %.4f' % AUC, \n",
    "    \n",
    "    turns_record.append(turns)\n",
    "    loss_record.append(train_loss.data.numpy())\n",
    "    MS_loss_record.append(MS_train_loss.data.numpy())\n",
    "    train_acc_record.append(train_accuracy)\n",
    "    precision_record.append(precision)\n",
    "    recall_record.append(recall)\n",
    "    F1_record.append(F1)\n",
    "    MCC_record.append(MCC)\n",
    "    AUC_record.append(AUC)\n",
    "    Score_record.append(total_score)\n",
    "    \n",
    "    SP_softmax_time = (SP_softmax_time_part_stop - SP_softmax_time_part_start)\n",
    "    SP_predy_time = (SP_predy_time_part_stop - SP_predy_time_part_start)\n",
    "    SP_trainout_time = (SP_trainout_time_part_stop - SP_trainout_time_part_start)\n",
    "    \n",
    "    total_loss_time += ((loss_time_part_stop - loss_time_part_start) + SP_trainout_time)\n",
    "    total_MS_loss_time += ((MS_loss_time_part_stop - MS_loss_time_part_start) + SP_trainout_time + SP_softmax_time)\n",
    "    total_acc_time += ((acc_time_part_stop - acc_time_part_start) + SP_predy_time + SP_trainout_time)\n",
    "    total_precision_time += ((precision_time_part_stop - precision_time_part_start) + SP_predy_time + SP_trainout_time)\n",
    "    total_recall_time += ((recall_time_part_stop - recall_time_part_start) + SP_predy_time + SP_trainout_time)\n",
    "    total_F1_time += ((F1_time_part_stop - F1_time_part_start) + SP_predy_time + SP_trainout_time)\n",
    "    total_MCC_time += ((MCC_time_part_stop - MCC_time_part_start) + SP_predy_time + SP_trainout_time)\n",
    "    total_AUC_time += ((AUC_time_part_stop - AUC_time_part_start) + SP_softmax_time + SP_trainout_time)\n",
    "    total_Score_time += ((Score_time_part_stop - Score_time_part_start) + SP_softmax_time + SP_trainout_time)\n",
    "\n",
    "print('\\nAverage Time Cost: ', '\\nAcc: %.8f' % (total_acc_time/TURNS), '\\nF1: %.8f' % (total_F1_time/TURNS), \n",
    "      '\\nMCC: %.8f' % (total_MCC_time/TURNS), '\\nMS Loss: %.8f' % (total_MS_loss_time/TURNS), \n",
    "      '\\nCE Loss: %.8f' % (total_loss_time/TURNS), '\\nScore: %.8f' % (total_Score_time/TURNS))      \n",
    "#       '\\nPrecision: %.8f' % (total_precision_time/TURNS), '\\nRecall: %.8f' % (total_recall_time/TURNS), '\\nAUC: %.8f' % (total_AUC_time/TURNS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2f1ca702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss 归一化\n",
    "max_loss = 0\n",
    "max_MS_loss = 0\n",
    "max_train_acc = 0\n",
    "max_precision = 0\n",
    "max_recall = 0\n",
    "max_F1 = 0\n",
    "max_MCC = 0\n",
    "max_AUC = 0\n",
    "max_Score = 0\n",
    "\n",
    "for i in range(len(turns_record)):\n",
    "    if loss_record[i] > max_loss:\n",
    "        max_loss = loss_record[i]\n",
    "    if MS_loss_record[i] > max_MS_loss:\n",
    "        max_MS_loss = MS_loss_record[i]\n",
    "#     if train_acc_record[i] > max_train_acc:\n",
    "#         max_train_acc = train_acc_record[i]\n",
    "#     if precision_record[i] > max_precision:\n",
    "#         max_precision = precision_record[i]\n",
    "#     if recall_record[i] > max_recall:\n",
    "#         max_recall = recall_record[i]\n",
    "#     if F1_record[i] > max_F1:\n",
    "#         max_F1 = F1_record[i]\n",
    "#     if AUC_record[i] > max_AUC:\n",
    "#         max_AUC = AUC_record[i]\n",
    "    if Score_record[i] > max_Score:\n",
    "        max_Score = Score_record[i]    \n",
    "\n",
    "for i in range(len(loss_record)):\n",
    "    loss_record[i] = loss_record[i]/max_loss\n",
    "    MS_loss_record[i] = MS_loss_record[i]/max_MS_loss\n",
    "#     train_acc_record[i] = train_acc_record[i]/max_train_acc\n",
    "#     precision_record[i] = precision_record[i]/max_precision\n",
    "#     recall_record[i] = recall_record[i]/max_recall\n",
    "#     F1_record[i] = F1_record[i]/max_F1\n",
    "#     AUC_record[i] = AUC_record[i]/max_AUC\n",
    "    Score_record[i] = Score_record[i]/max_Score\n",
    "    \n",
    "\n",
    "# plt.plot(turns_record, precision_record, '-')\n",
    "# plt.plot(turns_record, recall_record, '-')\n",
    "plt.plot(turns_record, train_acc_record, '.', color = 'tab:green', label='ACC')\n",
    "plt.plot(turns_record, F1_record, '.', color = 'b', label='F1') # lightpink\n",
    "plt.plot(turns_record, MCC_record, '.', color = 'm', label='MCC')\n",
    "# plt.plot(turns_record, AUC_record, '-')\n",
    "plt.plot(turns_record, MS_loss_record, '.', color = 'tab:cyan', label='MS') # turquoise\n",
    "plt.plot(turns_record, loss_record, '.', color = 'r', label='CE') # blueviolet\n",
    "plt.plot(turns_record, Score_record, '.', color = 'orange', label='MPWS')\n",
    "\n",
    "# 显示标签，如果不加这句，即使在plot中加了label='一些数字'的参数，最终还是不会显示标签\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc=2)\n",
    "\n",
    "LABEL = 'Exp 2'\n",
    "plt.xlabel(f\"{LABEL}. {NAME}\")\n",
    "\n",
    "plt.savefig(f'../Savefig/{LABEL}.png', bbox_inches='tight', dpi=600)  # 保存该图片\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "29598954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_acc_record_df = pd.DataFrame(train_acc_record)\n",
    "F1_record_df = pd.DataFrame(F1_record)\n",
    "MCC_record_df = pd.DataFrame(MCC_record)\n",
    "MS_loss_record_df = pd.DataFrame(MS_loss_record)\n",
    "loss_record_df = pd.DataFrame(loss_record)\n",
    "Score_record_df = pd.DataFrame(Score_record)\n",
    "\n",
    "data_df = pd.concat([train_acc_record_df, F1_record_df, MCC_record_df, MS_loss_record_df, loss_record_df, Score_record_df], axis=1)\n",
    "data_df.columns = ['Accuracy', 'F1-score', 'MCC', 'Mean Squared', 'Cross Entropy', 'MPWS']  # head\n",
    "\n",
    "writer = pd.ExcelWriter(f\"../Records/{LABEL}. {NAME}.xlsx\")\n",
    "data_df.to_excel(writer,'page_1')\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20e150e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
